{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268b4496",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52354a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sed' は、内部コマンドまたは外部コマンド、\n",
      "操作可能なプログラムまたはバッチ ファイルとして認識されていません。\n"
     ]
    }
   ],
   "source": [
    "! sed 's/\\r$//g' data/ai.ja.txt | cabocha > data/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b148b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ginza -f cabocha data/ai.ja.txt > data/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a3787",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "709438c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'surface': '人工知能', 'base': '人工知能', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '（', 'base': '（', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': 'じん', 'base': 'じん', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': 'こうち', 'base': 'こうち', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': 'のう', 'base': 'のう', 'pos': '助詞', 'pos1': '終助詞', 'application_type': False}\n",
      "{'surface': '、', 'base': '、', 'pos': '補助記号', 'pos1': '読点', 'application_type': False}\n",
      "{'surface': '、', 'base': '、', 'pos': '補助記号', 'pos1': '読点', 'application_type': False}\n",
      "{'surface': 'AI', 'base': 'AI', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '〈', 'base': '〈', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': 'エーアイ', 'base': 'エーアイ', 'pos': '名詞', 'pos1': '固有名詞', 'application_type': False}\n",
      "{'surface': '〉', 'base': '〉', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': '）', 'base': ')', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'と', 'base': 'と', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': 'は', 'base': 'は', 'pos': '助詞', 'pos1': '係助詞', 'application_type': False}\n",
      "{'surface': '、', 'base': '、', 'pos': '補助記号', 'pos1': '読点', 'application_type': False}\n",
      "{'surface': '「', 'base': '「', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '『', 'base': '『', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '計算', 'base': '計算', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': True}\n",
      "{'surface': '（', 'base': '（', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '）', 'base': ')', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': '』', 'base': '』', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'と', 'base': 'と', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': 'いう', 'base': 'いう', 'pos': '動詞', 'pos1': '一般', 'application_type': False}\n",
      "{'surface': '概念', 'base': '概念', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': 'と', 'base': 'と', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': '『', 'base': '『', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': 'コンピュータ', 'base': 'コンピュータ', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '（', 'base': '（', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '）', 'base': ')', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': '』', 'base': '』', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'と', 'base': 'と', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': 'いう', 'base': 'いう', 'pos': '動詞', 'pos1': '一般', 'application_type': False}\n",
      "{'surface': '道具', 'base': '道具', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': 'を', 'base': 'を', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': '用い', 'base': '用いる', 'pos': '動詞', 'pos1': '一般', 'application_type': False}\n",
      "{'surface': 'て', 'base': 'て', 'pos': '助詞', 'pos1': '接続助詞', 'application_type': False}\n",
      "{'surface': '『', 'base': '『', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '知能', 'base': '知能', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '』', 'base': '』', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'を', 'base': 'を', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': '研究', 'base': '研究', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': True}\n",
      "{'surface': 'する', 'base': 'する', 'pos': '動詞', 'pos1': '非自立可能', 'application_type': False}\n",
      "{'surface': '計算機科学', 'base': '計算機科学', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '（', 'base': '（', 'pos': '補助記号', 'pos1': '括弧開', 'application_type': False}\n",
      "{'surface': '）', 'base': ')', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'の', 'base': 'の', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': '一', 'base': '一', 'pos': '名詞', 'pos1': '数詞', 'application_type': False}\n",
      "{'surface': '分野', 'base': '分野', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '」', 'base': '」', 'pos': '補助記号', 'pos1': '括弧閉', 'application_type': False}\n",
      "{'surface': 'を', 'base': 'を', 'pos': '助詞', 'pos1': '格助詞', 'application_type': False}\n",
      "{'surface': '指す', 'base': '指す', 'pos': '動詞', 'pos1': '一般', 'application_type': False}\n",
      "{'surface': '語', 'base': '語', 'pos': '名詞', 'pos1': '普通名詞', 'application_type': False}\n",
      "{'surface': '。', 'base': '。', 'pos': '補助記号', 'pos1': '句点', 'application_type': False}\n"
     ]
    }
   ],
   "source": [
    "class Morph:\n",
    "    def __init__(self, morpheme):\n",
    "        surface, morphemes, _ = morpheme.split(\"\\t\")\n",
    "        morphemes = morphemes.split(\",\")\n",
    "        self.surface = surface\n",
    "        self.base = morphemes[6]\n",
    "        self.pos = morphemes[0]\n",
    "        self.pos1 = morphemes[1]\n",
    "        if morphemes[2] == \"サ変可能\":\n",
    "            self.application_type = True\n",
    "        else:\n",
    "            self.application_type = False\n",
    "        \n",
    "sen_morphemes = []\n",
    "morphemes = []\n",
    "\n",
    "path = \"data/ai.ja.txt.parsed\"\n",
    "with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        if line[0] == \"*\" or line == \"\\n\":\n",
    "            continue\n",
    "        elif line == \"EOS\\n\":\n",
    "            sen_morphemes.append(morphemes)\n",
    "            morphemes = []\n",
    "            continue\n",
    "        morphemes.append(Morph(line))\n",
    "        #print(morphemes)\n",
    "for i in sen_morphemes[1]:\n",
    "    print(vars(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38f2bd",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d186ec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 from [] to 1\n",
      "人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という\n",
      "1 from [0] to 2\n",
      "概念と\n",
      "2 from [1] to 3\n",
      "『コンピュータ（）』という\n",
      "3 from [2] to 4\n",
      "道具を\n",
      "4 from [3] to 6\n",
      "用いて\n",
      "5 from [] to 6\n",
      "『知能』を\n",
      "6 from [4, 5] to 7\n",
      "研究する\n",
      "7 from [6] to 8\n",
      "計算機科学（）の一分野」を\n",
      "8 from [7] to 9\n",
      "指す\n",
      "9 from [8, 9] to -1\n",
      "語。\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst, chunk_num):\n",
    "        self.morphs = morphs\n",
    "        self.dst = int(dst[:-1])\n",
    "        self.srcs = []\n",
    "        self.chunk_num = chunk_num\n",
    "        \n",
    "    def noun_masked_surface(self, mask, dst=False):\n",
    "        '''名詞を指定文字(mask)でマスクした表層形を返す\n",
    "        dstがTrueの場合は最左の名詞をマスクした以降は切り捨てて返す\n",
    "\n",
    "        戻り値：\n",
    "        名詞をマスクした表層形\n",
    "        '''\n",
    "        result = ''\n",
    "        for morph in self.morphs:\n",
    "            if morph.pos != '記号':\n",
    "                if morph.pos == '名詞':\n",
    "                    result += mask\n",
    "                    if dst:\n",
    "                        return result\n",
    "                    mask = ''       # 最初に見つけた名詞をマスク、以降の名詞は除去\n",
    "                else:\n",
    "                    result += morph.surface\n",
    "        return result\n",
    "    \n",
    "    def normalized_surface(self):\n",
    "        '''句読点などの記号を除いた表層形'''\n",
    "        result = ''\n",
    "        for morph in self.morphs:\n",
    "            if morph.pos != '記号':\n",
    "                result += morph.surface\n",
    "        return result\n",
    "        \n",
    "chunk_flag = False\n",
    "morphs = []\n",
    "Chunks = []\n",
    "Sentence = []\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        if line[0] == \"*\":\n",
    "            if chunk_flag:\n",
    "                Chunks.append(Chunk(morphs, dst, chunk_num))\n",
    "                morphs = []\n",
    "            else:\n",
    "                chunk_flag = True\n",
    "            dst = line.split()[2]\n",
    "            chunk_num = int(line.split()[1])\n",
    "        elif line == \"EOS\\n\":\n",
    "            Chunks.append(Chunk(morphs, dst, chunk_num))\n",
    "            Sentence.append(Chunks)\n",
    "            Chunks = []\n",
    "            morphs = []\n",
    "            chunk_flag = False\n",
    "        else:\n",
    "            morphs.append(Morph(line))\n",
    "# 係り先-1は係り先なし\n",
    "# Sentenceでは文章区切り、その中にChunks区切り、その中に各チャンク \n",
    "\"\"\"Sen[\n",
    "        Chunks[\n",
    "            Chunk{morphs,dst,srcs[],chunk_num},\n",
    "            Chunk,\n",
    "            ],\n",
    "        Chunks[\n",
    "            Chunk,\n",
    "            Chunk,\n",
    "            ]\n",
    "       ]\n",
    "\"\"\"\n",
    "\n",
    "for chunks in Sentence:\n",
    "    for i in chunks:\n",
    "        if i.dst == \"-1\":\n",
    "            continue\n",
    "        else:\n",
    "            from_num = i.chunk_num\n",
    "            to_num = i.dst\n",
    "            #print(from_num, to_num)\n",
    "            chunks[int(to_num)].srcs.append(from_num)\n",
    "\n",
    "chunks = Sentence[1]\n",
    "for i in chunks:\n",
    "    if i.dst != \"-1D\":\n",
    "        print(i.chunk_num, \"from\", i.srcs, \"to\", i.dst)\n",
    "    else:\n",
    "        print(i.chunk_num, \"from\", i.srcs, \"to None\",)\n",
    "    for l in i.morphs:\n",
    "        print(l.surface, end=\"\")\n",
    "    print('')\n",
    "print(\"EOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ccf0b9",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d6257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/42ans.txt\",\"w\", encoding=\"utf-8\")\n",
    "for chunks in Sentence:\n",
    "    for i in chunks:\n",
    "        if i.dst and i.dst != \"-1D\":\n",
    "            ans = \"\"\n",
    "            for l in i.morphs:\n",
    "                ans += l.surface\n",
    "            to = i.dst[:-1]\n",
    "            to_chunk = chunks[int(to)]\n",
    "            #print(\"\\t\", end=\"\")\n",
    "            for l in to_chunk.morphs:\n",
    "                ans += l.surface\n",
    "            ans += \"\\n\"\n",
    "            f.write(ans)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8064e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' は、内部コマンドまたは外部コマンド、\n",
      "操作可能なプログラムまたはバッチ ファイルとして認識されていません。\n"
     ]
    }
   ],
   "source": [
    "!cat data/42ans.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7902c",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6737c7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t"
     ]
    }
   ],
   "source": [
    "f = open(\"data/43ans.txt\",\"w\", encoding=\"utf-8\")\n",
    "import string\n",
    "for chunks in Sentence:\n",
    "    for i in chunks:\n",
    "        noun = False\n",
    "        vorb = False\n",
    "        for morph in i.morphs:\n",
    "            if morph.pos == \"名詞\":\n",
    "                noun = True\n",
    "        if noun:\n",
    "            to =i.dst[:-1]\n",
    "            to_chunk = chunks[int(to)]\n",
    "            for morph in to_chunk.morphs:\n",
    "                if morph.pos == \"動詞\":\n",
    "                    vorb = True\n",
    "        if noun and vorb:\n",
    "            for morph in i.morphs:\n",
    "                if morph.pos1 == \"句点\" or morph.pos1 == \"読点\":\n",
    "                    continue\n",
    "                f.write(morph.surface.translate(str.maketrans('', '', string.punctuation))+\"\\n\")\n",
    "            print(\"\\t\",end=\"\")\n",
    "            for morph in to_chunk.morphs:\n",
    "                if morph.pos1 == \"句点\" or morph.pos1 == \"読点\":\n",
    "                    continue\n",
    "                f.write(morph.surface.translate(str.maketrans('', '', string.punctuation))+\"\\n\")\n",
    "        noun = False\n",
    "        vorb = False\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76fac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "概念\n",
      "と\n",
      "『\n",
      "コンピュータ\n",
      "（\n",
      "）\n",
      "』\n",
      "と\n",
      "いう\n",
      "道具\n"
     ]
    }
   ],
   "source": [
    "!cat data/43ans.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefafa2",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3aa45f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Graph\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02c92104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"648pt\" height=\"620pt\"\n",
       " viewBox=\"0.00 0.00 647.54 620.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 616)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-616 643.54,-616 643.54,4 -4,4\"/>\n",
       "<!-- 人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.77\" cy=\"-594\" rx=\"319.54\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.77\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という</text>\n",
       "</g>\n",
       "<!-- 概念と -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>概念と</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.77\" cy=\"-522\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.77\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">概念と</text>\n",
       "</g>\n",
       "<!-- 人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という&#45;&gt;概念と -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という&#45;&gt;概念と</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.77,-575.7C319.77,-567.98 319.77,-558.71 319.77,-550.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.27,-550.1 319.77,-540.1 316.27,-550.1 323.27,-550.1\"/>\n",
       "</g>\n",
       "<!-- 『コンピュータ（）』という -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>『コンピュータ（）』という</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.77\" cy=\"-450\" rx=\"130.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.77\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">『コンピュータ（）』という</text>\n",
       "</g>\n",
       "<!-- 概念と&#45;&gt;『コンピュータ（）』という -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>概念と&#45;&gt;『コンピュータ（）』という</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.77,-503.7C319.77,-495.98 319.77,-486.71 319.77,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.27,-478.1 319.77,-468.1 316.27,-478.1 323.27,-478.1\"/>\n",
       "</g>\n",
       "<!-- 道具を -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>道具を</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.77\" cy=\"-378\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.77\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">道具を</text>\n",
       "</g>\n",
       "<!-- 『コンピュータ（）』という&#45;&gt;道具を -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>『コンピュータ（）』という&#45;&gt;道具を</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.77,-431.7C319.77,-423.98 319.77,-414.71 319.77,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.27,-406.1 319.77,-396.1 316.27,-406.1 323.27,-406.1\"/>\n",
       "</g>\n",
       "<!-- 用いて -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>用いて</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.77\" cy=\"-306\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.77\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">用いて</text>\n",
       "</g>\n",
       "<!-- 道具を&#45;&gt;用いて -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>道具を&#45;&gt;用いて</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.77,-359.7C319.77,-351.98 319.77,-342.71 319.77,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.27,-334.1 319.77,-324.1 316.27,-334.1 323.27,-334.1\"/>\n",
       "</g>\n",
       "<!-- 研究する -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>研究する</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"376.77\" cy=\"-234\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.77\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">研究する</text>\n",
       "</g>\n",
       "<!-- 用いて&#45;&gt;研究する -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>用いて&#45;&gt;研究する</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M332.99,-288.76C340.08,-280.06 348.97,-269.15 356.87,-259.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.63,-261.6 363.23,-251.63 354.2,-257.18 359.63,-261.6\"/>\n",
       "</g>\n",
       "<!-- 計算機科学（）の一分野」を -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>計算機科学（）の一分野」を</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"376.77\" cy=\"-162\" rx=\"131.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.77\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算機科学（）の一分野」を</text>\n",
       "</g>\n",
       "<!-- 研究する&#45;&gt;計算機科学（）の一分野」を -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>研究する&#45;&gt;計算機科学（）の一分野」を</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.77,-215.7C376.77,-207.98 376.77,-198.71 376.77,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.27,-190.1 376.77,-180.1 373.27,-190.1 380.27,-190.1\"/>\n",
       "</g>\n",
       "<!-- 『知能』を -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>『知能』を</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"433.77\" cy=\"-306\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"433.77\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">『知能』を</text>\n",
       "</g>\n",
       "<!-- 『知能』を&#45;&gt;研究する -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>『知能』を&#45;&gt;研究する</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.26,-288.41C413.24,-279.78 404.51,-269.06 396.72,-259.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"399.21,-257.01 390.18,-251.47 393.78,-261.43 399.21,-257.01\"/>\n",
       "</g>\n",
       "<!-- 指す -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>指す</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"376.77\" cy=\"-90\" rx=\"29.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.77\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">指す</text>\n",
       "</g>\n",
       "<!-- 計算機科学（）の一分野」を&#45;&gt;指す -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>計算機科学（）の一分野」を&#45;&gt;指す</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.77,-143.7C376.77,-135.98 376.77,-126.71 376.77,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.27,-118.1 376.77,-108.1 373.27,-118.1 380.27,-118.1\"/>\n",
       "</g>\n",
       "<!-- 語。 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>語。</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"376.77\" cy=\"-18\" rx=\"29.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.77\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">語。</text>\n",
       "</g>\n",
       "<!-- 指す&#45;&gt;語。 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>指す&#45;&gt;語。</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.77,-71.7C376.77,-63.98 376.77,-54.71 376.77,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.27,-46.1 376.77,-36.1 373.27,-46.1 380.27,-46.1\"/>\n",
       "</g>\n",
       "<!-- 語。&#45;&gt;語。 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>語。&#45;&gt;語。</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M398.15,-30.55C411.41,-33.57 424.02,-29.39 424.02,-18 424.02,-9.64 417.22,-5.16 408.35,-4.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.81,-1.1 398.15,-5.45 408.42,-8.07 407.81,-1.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fb2602ebc10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Digraph(format='png')\n",
    "chunks = Sentence[1]\n",
    "for i in chunks:\n",
    "    chunk_sen = \"\"\n",
    "    for morph in i.morphs:\n",
    "        chunk_sen += morph.surface\n",
    "    to = int(i.dst[:-1])\n",
    "    to_chunk = chunks[to]\n",
    "    to_chunk_sen = \"\"\n",
    "    for morph in to_chunk.morphs:\n",
    "        to_chunk_sen += morph.surface\n",
    "    if not tree.node(chunk_sen):\n",
    "        tree.node(chunk_sen)\n",
    "    if not tree.node(to_chunk_sen):\n",
    "        tree.node(to_chunk_sen)\n",
    "    tree.edge(chunk_sen, to_chunk_sen)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec95f99",
   "metadata": {},
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "述語に係る助詞を格とする\n",
    "述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "作り出す\tで は を\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a52bb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/prob45.txt\", \"w\", encoding=\"utf-8\")\n",
    "for chunks in Sentence:\n",
    "    for chunk in chunks:\n",
    "        to_dict = dict()\n",
    "        for morph in chunk.morphs:\n",
    "            if morph.pos == \"助詞\":\n",
    "                to = int(chunk.dst[:-1])\n",
    "                to_chunk = chunks[to]\n",
    "                #print(morph.base)\n",
    "                for to_morph in to_chunk.morphs:\n",
    "                    if to_morph.pos == \"動詞\":\n",
    "                        #print(to_morph.base)\n",
    "                        if not to_morph.base in to_dict:\n",
    "                            to_dict[to_morph.base] = [morph.base]\n",
    "                            \n",
    "                        else:\n",
    "                            k= to_dict[to_morph.base]\n",
    "                            k.append(morph.base)\n",
    "                            to_dict[to_morph.base] = k\n",
    "        for key,value in to_dict.items():\n",
    "            value.sort()\n",
    "            comb = key + \"\\t\" + \"\\t\".join(value) +\"\\n\"\n",
    "            file.write(comb)\n",
    "            #print(key, value)\n",
    "            #print(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c95b2032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 する\tを\n",
      "  61 する\tが\n",
      "  58 いる\tて\n",
      "  49 する\tに\n",
      "  48 する\tて\n",
      "  30 する\tは\n",
      "  27 する\tと\n",
      "  27 する\tで\n",
      "  27 いる\tが\n",
      "  20 いる\tを\n"
     ]
    }
   ],
   "source": [
    "!cat data/prob45.txt | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ed6fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12 行う\tを\n",
      "   6 行う\tに\n",
      "   6 行う\tて\n",
      "   3 行う\tは\n",
      "   3 行う\tで\n",
      "   3 行う\tが\n",
      "   2 行う\tに\tは\n",
      "   1 行う\tまで\n",
      "   1 行う\tなど\n",
      "   1 行う\tの\n"
     ]
    }
   ],
   "source": [
    "!cat data/prob45.txt | grep \"行う\" | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b867e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11 なる\tと\n",
      "   9 なる\tに\n",
      "   9 なる\tが\n",
      "   7 なる\tは\n",
      "   7 なる\tて\n",
      "   3 なる\tから\n",
      "   3 なる\tに\tは\n",
      "   2 なる\tで\n",
      "   1 無くなる\tは\n",
      "   1 異なる\tで\n"
     ]
    }
   ],
   "source": [
    "!cat data/prob45.txt | grep \"なる\" | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "321d6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2 与える\tが\n",
      "   1 与える\tなど\tに\n"
     ]
    }
   ],
   "source": [
    "!cat data/prob45.txt | grep \"与える\" | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae05ca0",
   "metadata": {},
   "source": [
    "## 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ec6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/46ans.txt\",\"w\", encoding=\"utf-8\")\n",
    "for chunks in Sentence:\n",
    "    for chunk in chunks:\n",
    "        chunk_list = []\n",
    "        to_dict = dict()\n",
    "        for morph in chunk.morphs:\n",
    "            chunk_list.append(morph.surface)\n",
    "            if morph.pos == \"助詞\":\n",
    "                to = int(chunk.dst[:-1])\n",
    "                to_chunk = chunks[to]\n",
    "                #print(morph.base)\n",
    "                for to_morph in to_chunk.morphs:\n",
    "                    if to_morph.pos == \"動詞\":\n",
    "                        #print(to_morph.base)\n",
    "                        if not to_morph.base in to_dict:\n",
    "                            to_dict[to_morph.base] = [[morph.base],[\"\".join(chunk_list)]]\n",
    "                            chunk_list = []\n",
    "                            \n",
    "                        else:\n",
    "                            k= to_dict[to_morph.base][0]\n",
    "                            j= to_dict[to_morph.base][1]\n",
    "                            k.append(morph.base)\n",
    "                            j.append(\"\".join(chunk_list))\n",
    "                            chunk_list = []\n",
    "                            to_dict[to_morph.base] = [k,j]\n",
    "        for key,value in to_dict.items():\n",
    "            value[0].sort()\n",
    "            comb = key + \"\\t\" + \"\\t\".join(value[0]) + \"\\t\" + \"\\t\".join(value[1])  +\"\\n\"\n",
    "            f.write(comb)\n",
    "            #print(key, value)\n",
    "            #print(comb)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2649457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "いう\tと\t概念と\n",
      "用いる\tを\t道具を\n",
      "する\tて\t用いて\n",
      "する\tを\t『知能』を\n",
      "指す\tの\tを\t計算機科学（）の\t一分野」を\n",
      "代わる\tを\t知的行動を\n",
      "代わる\tに\t人間に\n",
      "行う\tて\t代わって\n",
      "行う\tに\tコンピューターに\n",
      "する\tは\tまたは\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat data/46ans.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e0769",
   "metadata": {},
   "source": [
    "## 47. 機能動詞構文のマイニング\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "例えば「また、自らの経験を元に学習を行う強化学習という手法もある。」という文から，以下の出力が得られるはずである．\n",
    "\n",
    "学習を行う\tに を\t元に 経験を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2204b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行動を代わる\tを\t知的行動を\n",
      "設計を関する\tや\t設計や\n",
      "研究をする\tと\tも\t研究分野」と\tも\n",
      "解説を述べる\tで\t解説で\n",
      "解説をいる\tで\t\n",
      "判断をする\tを\t推論・判断を\n",
      "解析をする\tて\t解析して\n",
      "抽出をする\tたり\t検出・抽出したり\n",
      "認識をある\tが\t画像認識等が\n",
      "会議をする\tで\tダートマス会議で\n",
      "処理を用いる\tを\t記号処理を\n",
      "記述をする\tを\t記述を\n",
      "研究をいう\tで\tの\t研究で\tの\n",
      "思考を呼ぶ\tも\t思考ルーチンも\n",
      "思考をある\tも\t\n",
      "プログラムを出す\tが\tプログラム（人工無脳）が\n",
      "実現をなる\tは\t実現は\n",
      "記述をなる\tが\t記述が\n",
      "利用をする\tが\t利用が\n",
      "利用をいる\tが\t\n",
      "実現をする\tの\tへ\t実現へ\tの\n",
      "アプローチを知る\tて\tと\tは\tアプローチと\tして\tは\n",
      "アプローチをいる\tて\tと\tは\t\t\t\n",
      "アプローチを知る\tも\tアプローチも\n",
      "アプローチをいる\tも\t\n",
      "明示をある\tに\t記号的明示性に\n",
      "サポートを集める\tが\t「サポートベクターマシン」が\n",
      "注目を集める\tを\t注目を\n",
      "学習を行う\tを\t学習を\n",
      "登場をよる\tと\t登場と\n",
      "登場を行く\tに\t登場に\n",
      "流行を超える\tを\t流行を\n",
      "浸透を行く\tて\t浸透して\n",
      "到達をなる\tなど\t到達するなど\n",
      "ものをある\tが\tものが\n",
      "計算をする\tは\t計算知能（CI）は\n",
      "計算をいる\tは\t\n",
      "学習を繰り返す\tを\t学習を\n",
      "調整をする\tの\tしている（例えば、パラメータ調整、コネクショニズムの\n",
      "調整をいる\tの\t\n",
      "学習をある\tは\t学習は\n",
      "経験を基づく\tに\t経験に\n",
      "関係をする\tて\t関係して\n",
      "関係をいる\tて\t\n",
      "ものをある\tが\tものが\n"
     ]
    }
   ],
   "source": [
    "for chunks in Sentence[:20]:\n",
    "    for chunk in chunks:\n",
    "        sahen_flag = False\n",
    "        chunk_list = []\n",
    "        to_dict = dict()\n",
    "        for morph in chunk.morphs:\n",
    "            chunk_list.append(morph.surface)\n",
    "            if morph.pos == \"名詞\" and morph.application_type:\n",
    "                sahen_flag = True\n",
    "                noun = morph.base\n",
    "            if morph.pos == \"助詞\":\n",
    "                to = int(chunk.dst[:-1])\n",
    "                to_chunk = chunks[to]\n",
    "                #print(morph.base)\n",
    "                for to_morph in to_chunk.morphs:\n",
    "                    if to_morph.pos == \"動詞\":\n",
    "                        #print(to_morph.base)\n",
    "                        if sahen_flag:\n",
    "                            if not to_morph.base in to_dict:\n",
    "                                to_dict[to_morph.base] = [[morph.base],[\"\".join(chunk_list)], noun]\n",
    "                                chunk_list = []\n",
    "                            \n",
    "                            else:\n",
    "                                k= to_dict[to_morph.base][0]\n",
    "                                j= to_dict[to_morph.base][1]\n",
    "                                k.append(morph.base)\n",
    "                                j.append(\"\".join(chunk_list))\n",
    "                                chunk_list = []\n",
    "                                to_dict[to_morph.base] = [k,j,noun]\n",
    "        for key,value in to_dict.items():\n",
    "            value[0].sort()\n",
    "            comb = value[2] + \"を\" +key + \"\\t\" + \"\\t\".join(value[0]) + \"\\t\" + \"\\t\".join(value[1])\n",
    "            #file.write(comb)\n",
    "            #print(key, value)\n",
    "            print(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba7150",
   "metadata": {},
   "source": [
    "## 48. 名詞から根へのパスの抽出\n",
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "各文節は（表層形の）形態素列で表現する\n",
    "パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "ジョンマッカーシーは -> 作り出した\n",
    "AIに関する -> 最初の -> 会議で -> 作り出した\n",
    "最初の -> 会議で -> 作り出した\n",
    "会議で -> 作り出した\n",
    "人工知能という -> 用語を -> 作り出した\n",
    "用語を -> 作り出した\n",
    "KNPを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "ジョンマッカーシーは -> 作り出した\n",
    "ＡＩに -> 関する -> 会議で -> 作り出した\n",
    "会議で -> 作り出した\n",
    "人工知能と -> いう -> 用語を -> 作り出した\n",
    "用語を -> 作り出した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08975cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョン・マッカーシーは -> 作り出した。\n",
      "AIに関する -> 会議で -> 作り出した。\n",
      "最初の -> 会議で -> 作り出した。\n",
      "会議で -> 作り出した。\n",
      "「人工知能」という -> 用語を -> 作り出した。\n",
      "用語を -> 作り出した。\n"
     ]
    }
   ],
   "source": [
    "def func_tree(to,chunks):\n",
    "    if len(chunks) <= to:\n",
    "        return\n",
    "    to_chunk = chunks[to]\n",
    "    print(\" -> \", end=\"\")\n",
    "    for to_morph in to_chunk.morphs:\n",
    "        print(to_morph.surface, end=\"\")\n",
    "    to = int(to_chunk.dst[:-1])\n",
    "    if to != -1:\n",
    "        func_tree(to, chunks)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "\n",
    "for chunk in Sentence[33]:\n",
    "    to_dict = dict()\n",
    "    noun_flag = False\n",
    "    for morph in chunk.morphs:\n",
    "        if morph.pos == \"名詞\":\n",
    "            to = int(chunk.dst[:-1])\n",
    "            noun_flag = True\n",
    "    if noun_flag:\n",
    "        for morph in chunk.morphs:\n",
    "            print(morph.surface, end=\"\")\n",
    "        if to!= -1:\n",
    "                func_tree(to,Sentence[33])\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3de18b",
   "metadata": {},
   "source": [
    "## 49. 名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がi\n",
    "とj\n",
    "（i<j\n",
    "）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "\n",
    "問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n",
    "文節i\n",
    "とj\n",
    "に含まれる名詞句はそれぞれ，XとYに置換する\n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "\n",
    "文節i\n",
    "から構文木の根に至る経路上に文節j\n",
    "が存在する場合: 文節i\n",
    "から文節j\n",
    "のパスを表示\n",
    "上記以外で，文節i\n",
    "と文節j\n",
    "から構文木の根に至る経路上で共通の文節k\n",
    "で交わる場合: 文節i\n",
    "から文節k\n",
    "に至る直前のパスと文節j\n",
    "から文節k\n",
    "に至る直前までのパス，文節k\n",
    "の内容を” | “で連結して表示\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
    "Xは | Yの -> 会議で | 作り出した\n",
    "Xは | Yで | 作り出した\n",
    "Xは | Yという -> 用語を | 作り出した\n",
    "Xは | Yを | 作り出した\n",
    "Xに関する -> Yの\n",
    "Xに関する -> 最初の -> Yで\n",
    "Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
    "Xの -> Yで\n",
    "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xの -> 会議で | Yを | 作り出した\n",
    "Xで | Yという -> 用語を | 作り出した\n",
    "Xで | Yを | 作り出した\n",
    "Xという -> Yを\n",
    "KNPを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "Xは | Yに -> 関する -> 会議で | 作り出した。\n",
    "Xは | Yで | 作り出した。\n",
    "Xは | Yと -> いう -> 用語を | 作り出した。\n",
    "Xは | Yを | 作り出した。\n",
    "Xに -> 関する -> Yで\n",
    "Xに -> 関する -> 会議で | Yと -> いう -> 用語を | 作り出した。\n",
    "Xに -> 関する -> 会議で | Yを | 作り出した。\n",
    "Xで | Yと -> いう -> 用語を | 作り出した。\n",
    "Xで | Yを | 作り出した。\n",
    "Xと -> いう -> Yを"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e0f329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果ファイル作成\n",
    "with open(\"data/49ans.txt\", mode='w') as f:\n",
    "\n",
    "    # 1文ずつリスト作成\n",
    "    for chunks in Sentence:\n",
    "        indexs_noun = []\n",
    "        for chunk in chunks:\n",
    "            # 名詞を含むchunkに限定した、chunksにおけるインデックスのリストを作成\n",
    "            for morph in chunk.morphs:\n",
    "                if morph.pos == \"名詞\":\n",
    "                    indexs_noun.append(chunk.chunk_num)\n",
    "                # 2つ以上ある？\n",
    "        if len(indexs_noun) < 2:\n",
    "            continue\n",
    "        # 名詞を含むchunkの組み合わせを総当りでチェック\n",
    "        for i, index_x in enumerate(indexs_noun[:-1]):\n",
    "            for index_y in indexs_noun[i + 1:]:\n",
    "                meet_y = False          # Yにぶつかった？\n",
    "                index_dup = -1          # XとYの経路がぶつかったchunkのindex\n",
    "                routes_x = set()        # Xの経路チェック用\n",
    "                # 名詞Xから根に向かって、Yにぶつからないか調べながら探索\n",
    "                dst = chunks[index_x].dst\n",
    "                while dst != -1:\n",
    "                    if dst == index_y:\n",
    "                        meet_y = True           # Yにぶつかった\n",
    "                        break\n",
    "                    routes_x.add(dst)           # 経路チェックのために保存\n",
    "                    dst = chunks[dst].dst\n",
    "                # 名詞Yから根まで、Xの経路にぶつからないか調べながら探索\n",
    "                if not meet_y:\n",
    "                    dst = chunks[index_y].dst\n",
    "                    while dst != -1:\n",
    "                        if dst in routes_x:\n",
    "                            index_dup = dst     # Xの経路とぶつかった\n",
    "                            break\n",
    "                        else:\n",
    "                            dst = chunks[dst].dst\n",
    "                # 結果出力\n",
    "                if index_dup == -1:\n",
    "                    # XからYにぶつかるパターン\n",
    "                    f.write(chunks[index_x].noun_masked_surface('X'))\n",
    "                    dst = chunks[index_x].dst\n",
    "                    while dst != -1:\n",
    "                        if dst == index_y:\n",
    "                            f.write(\n",
    "                                    ' -> ' + chunks[dst].noun_masked_surface('Y', True))\n",
    "                            break\n",
    "                        else:\n",
    "                            f.write(\n",
    "                                    ' -> ' + chunks[dst].normalized_surface())\n",
    "                        dst = chunks[dst].dst\n",
    "                    f.write('\\n')\n",
    "                else:\n",
    "                    # 経路上の共通のchunkでぶつかるパターン\n",
    "                    # Xからぶつかる手前までを出力\n",
    "                    f.write(chunks[index_x].noun_masked_surface('X'))\n",
    "                    dst = chunks[index_x].dst\n",
    "                    while dst != index_dup:\n",
    "                        f.write(' -> ' + chunks[dst].normalized_surface())\n",
    "                        dst = chunks[dst].dst\n",
    "                    f.write(' | ')\n",
    "                    # Yからぶつかる手前までを出力\n",
    "                    f.write(chunks[index_y].noun_masked_surface('Y'))\n",
    "                    dst = chunks[index_y].dst\n",
    "                    while dst != index_dup:\n",
    "                        f.write(' -> ' + chunks[dst].normalized_surface())\n",
    "                        dst = chunks[dst].dst\n",
    "                    f.write(' | ')\n",
    "                    # ぶつかったchunkを出力\n",
    "                    f.write(chunks[index_dup].normalized_surface())\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1dabc294-0df9-4835-96df-3b8887009abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xから -> 監視する -> 政府支援の -> プロジェクトが -> 推し進められ、 -> 行わせ、 -> 顔認識 -> Y\r\n",
      "\r\n",
      "Xらは、 | Yの -> 軍事利用により -> 加速すると | 主張している。\r\n",
      "\r\n",
      "Xが -> 不可能な -> Y\r\n",
      "\r\n",
      "Xに | Yは | 採択するも\r\n",
      "\r\n",
      "Xなど -> 拡散させて -> 攻撃する -> ドローン兵器も -> Y\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/49ans.txt | tail -n 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
